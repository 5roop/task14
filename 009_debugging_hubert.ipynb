{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'models/*': No such file or directory\n",
      "Using custom data configuration default-9260442a7fe0355e\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eae169072c24a71bd113cf781b7ba72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classification problem with 5 classes: ['anger', 'fear', 'happiness', 'neutral', 'sadness']\n",
      "The target sampling rate: 16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "Some weights of the model checkpoint at facebook/hubert-large-ls960-ft were not used when initializing HubertForSpeechClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing HubertForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSpeechClassification were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using amp half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 702\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m5roop\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peterr/macocu/task14/wandb/run-20220907_102532-4udsvxr0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/5roop/huggingface/runs/4udsvxr0\" target=\"_blank\">models/facebook_hubert-large-ls960-ft_emotion_10_epochs_</a></strong> to <a href=\"https://wandb.ai/5roop/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1750/1750 16:04, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.258600</td>\n",
       "      <td>1.519196</td>\n",
       "      <td>0.415842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.076700</td>\n",
       "      <td>1.690176</td>\n",
       "      <td>0.445545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>1.153252</td>\n",
       "      <td>0.623762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.656300</td>\n",
       "      <td>1.225020</td>\n",
       "      <td>0.683168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.276100</td>\n",
       "      <td>1.310936</td>\n",
       "      <td>0.693069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.624300</td>\n",
       "      <td>1.607441</td>\n",
       "      <td>0.673267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>1.637533</td>\n",
       "      <td>0.707921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>1.784918</td>\n",
       "      <td>0.722772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.215200</td>\n",
       "      <td>1.870361</td>\n",
       "      <td>0.722772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>1.835797</td>\n",
       "      <td>0.737624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175/preprocessor_config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-e8347a4b4ad081a1\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-e8347a4b4ad081a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e7a0c7e0fa48eb8c87efbf170f0fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e2addb13cf4b4a8634158b3b53edec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function eval_model.<locals>.predict at 0x7fe9eb5c2f70> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a0be319f264b84af148d520d6581b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1cd582fe01726688\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba9865a6049420b9e5659dfb6b3911a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-72734b5613839aa0.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a042435c5e624364a0a794c4c70e3f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9260442a7fe0355e\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a403dc93cc402dba4f003e4257e75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classification problem with 5 classes: ['anger', 'fear', 'happiness', 'neutral', 'sadness']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/b53ed8747a5b37964a05edc916473cff56715a812925d9dc9da210fb78034a44.1926821bfae853fe61231002dd5438ad945f4005f0254f94cc34585e6a702ae4\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/preprocessor_config.json from cache at /home/peterr/.cache/huggingface/transformers/1a84c80cbd674725a664809a7b84a44f63215e0cfe72ead717aa2302869edb5d.d4484dc1c81456a2461485e7168b04347a7b9a4e3b1ef3aba723323b33e12326\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/b53ed8747a5b37964a05edc916473cff56715a812925d9dc9da210fb78034a44.1926821bfae853fe61231002dd5438ad945f4005f0254f94cc34585e6a702ae4\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/vocab.json from cache at /home/peterr/.cache/huggingface/transformers/d9b098b7eb8dd691982b067aafa2fc8a5fc7839a45b7ccc3abc775ad5e2a7903.8bb95990c4cc44068ae3d50c97a7e96b000a80e847578b125650dd57bf4ab6ce\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/tokenizer_config.json from cache at /home/peterr/.cache/huggingface/transformers/f62214d9f96320035803149844bdd96d0d8c656626d2214083c480a5e45a0c2e.ea28570bd84cc806dae8a5ad416aa9fb57e169b1bf6fce0386fd890fec53e6a0\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/special_tokens_map.json from cache at /home/peterr/.cache/huggingface/transformers/0dd9f421c5b57d7bce23fb1d1c182fd28779f145cd3b2dada47f3d2e2ecff47b.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd\n",
      "loading configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/b53ed8747a5b37964a05edc916473cff56715a812925d9dc9da210fb78034a44.1926821bfae853fe61231002dd5438ad945f4005f0254f94cc34585e6a702ae4\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/feature_extraction_utils.py:168: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "loading weights file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/pytorch_model.bin from cache at /home/peterr/.cache/huggingface/transformers/9db74ddedd45cb8cd6233e14aee9e5ba9297e9dccd82c67e69dc91c1f1396387.31d6b2d44978dea4ae1cc6e968eee22b751827772599354d66f27aca2af4bc00\n",
      "Some weights of the model checkpoint at facebook/hubert-xlarge-ls960-ft were not used when initializing HubertForSpeechClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing HubertForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSpeechClassification were not initialized from the model checkpoint at facebook/hubert-xlarge-ls960-ft and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using amp half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 702\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1750/1750 28:32, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.147900</td>\n",
       "      <td>1.492259</td>\n",
       "      <td>0.485149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.146500</td>\n",
       "      <td>0.903698</td>\n",
       "      <td>0.683168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.211900</td>\n",
       "      <td>1.242215</td>\n",
       "      <td>0.707921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.630300</td>\n",
       "      <td>1.071212</td>\n",
       "      <td>0.683168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.819300</td>\n",
       "      <td>1.092397</td>\n",
       "      <td>0.742574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>1.351161</td>\n",
       "      <td>0.757426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>1.508118</td>\n",
       "      <td>0.762376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>1.651767</td>\n",
       "      <td>0.747525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>1.684291</td>\n",
       "      <td>0.777228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>1.650334</td>\n",
       "      <td>0.787129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175/preprocessor_config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-e8347a4b4ad081a1\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-e8347a4b4ad081a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb5422bca344ba19ebb89ae55581324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-e8347a4b4ad081a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-bb440e43c1baa3de.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c422325209af43adbc1e87cb06a84422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1cd582fe01726688\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bccf7039374cf98bb61d075bb1faa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-72734b5613839aa0.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b209c0471515482f9f774ce46794a4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9260442a7fe0355e\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f05da3e99046a99ca9eb64072c2fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classification problem with 5 classes: ['anger', 'fear', 'happiness', 'neutral', 'sadness']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/6e6a66209ff036c1950c074bf469284b972c51d47a2b5616058492342c5aefed.757c0a4bd6fb6d02fc8d08d3765246a0dfceff43b5c30b6f89a37f5bc41cf9a9\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/preprocessor_config.json from cache at /home/peterr/.cache/huggingface/transformers/a5ddb07fdc2b1c071a4052b0770fc830bb2700d1e63e93d18d76d6afc7fbeb8c.d4484dc1c81456a2461485e7168b04347a7b9a4e3b1ef3aba723323b33e12326\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/6e6a66209ff036c1950c074bf469284b972c51d47a2b5616058492342c5aefed.757c0a4bd6fb6d02fc8d08d3765246a0dfceff43b5c30b6f89a37f5bc41cf9a9\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/vocab.json from cache at /home/peterr/.cache/huggingface/transformers/dcb65ab05f43e19e1d0c683e4ca2a5009f813c82b2e538d2f7bf61207bfa5a93.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/tokenizer_config.json from cache at /home/peterr/.cache/huggingface/transformers/6d379fd1e1c3bd71a723979c82cc04c4a06b6d027e2b359ba86c2526bca7a23c.ea28570bd84cc806dae8a5ad416aa9fb57e169b1bf6fce0386fd890fec53e6a0\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/special_tokens_map.json from cache at /home/peterr/.cache/huggingface/transformers/e905ddc20478dfb25fd1f9e8fe2783b83b30570baff6db8f7532d9fb6b93e66d.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd\n",
      "loading configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/6e6a66209ff036c1950c074bf469284b972c51d47a2b5616058492342c5aefed.757c0a4bd6fb6d02fc8d08d3765246a0dfceff43b5c30b6f89a37f5bc41cf9a9\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-779d51f3a8211705.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-07021d0fd665679f.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-0d3ac5bd36ffc2ce.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-10fe1a04e7e70c67.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-9a3e82c6ca94b4b8.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b90baf9b4e39741a.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b4e4dd45ce662e94.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-f8e1ae8a794e0b66.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/pytorch_model.bin from cache at /home/peterr/.cache/huggingface/transformers/3964c36efc75c1687db64aaf1d970beee48cd89e4a8c6b5bd072ca7ee9ff8cc5.bb6f85ae361fc3c32f100ac2335b4609e9f7135ced8e598265e36654b51d8471\n",
      "Some weights of the model checkpoint at facebook/hubert-large-ls960-ft were not used when initializing HubertForSpeechClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing HubertForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSpeechClassification were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using amp half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 702\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1750/1750 16:10, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.352400</td>\n",
       "      <td>1.286895</td>\n",
       "      <td>0.495050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.842300</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>0.529703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.856900</td>\n",
       "      <td>1.184742</td>\n",
       "      <td>0.618812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.591400</td>\n",
       "      <td>1.378073</td>\n",
       "      <td>0.618812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>1.563518</td>\n",
       "      <td>0.643564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.304600</td>\n",
       "      <td>1.652293</td>\n",
       "      <td>0.683168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.448900</td>\n",
       "      <td>1.960950</td>\n",
       "      <td>0.668317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.387700</td>\n",
       "      <td>1.940287</td>\n",
       "      <td>0.702970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>2.067034</td>\n",
       "      <td>0.702970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>2.031552</td>\n",
       "      <td>0.688119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175/preprocessor_config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-e8347a4b4ad081a1\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-e8347a4b4ad081a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a3e1b705cb4d3aad52649adaf1590e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-e8347a4b4ad081a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-bb440e43c1baa3de.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6e091cf50244389e181a8873b846e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1cd582fe01726688\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d8e3e8929e408f9c6bd55a64e62693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-72734b5613839aa0.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d279f25bc9de4475a3ae219736f39fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9260442a7fe0355e\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf409b302194e8183ab1daedf3cac94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classification problem with 5 classes: ['anger', 'fear', 'happiness', 'neutral', 'sadness']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/b53ed8747a5b37964a05edc916473cff56715a812925d9dc9da210fb78034a44.1926821bfae853fe61231002dd5438ad945f4005f0254f94cc34585e6a702ae4\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/preprocessor_config.json from cache at /home/peterr/.cache/huggingface/transformers/1a84c80cbd674725a664809a7b84a44f63215e0cfe72ead717aa2302869edb5d.d4484dc1c81456a2461485e7168b04347a7b9a4e3b1ef3aba723323b33e12326\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/b53ed8747a5b37964a05edc916473cff56715a812925d9dc9da210fb78034a44.1926821bfae853fe61231002dd5438ad945f4005f0254f94cc34585e6a702ae4\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/vocab.json from cache at /home/peterr/.cache/huggingface/transformers/d9b098b7eb8dd691982b067aafa2fc8a5fc7839a45b7ccc3abc775ad5e2a7903.8bb95990c4cc44068ae3d50c97a7e96b000a80e847578b125650dd57bf4ab6ce\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/tokenizer_config.json from cache at /home/peterr/.cache/huggingface/transformers/f62214d9f96320035803149844bdd96d0d8c656626d2214083c480a5e45a0c2e.ea28570bd84cc806dae8a5ad416aa9fb57e169b1bf6fce0386fd890fec53e6a0\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/special_tokens_map.json from cache at /home/peterr/.cache/huggingface/transformers/0dd9f421c5b57d7bce23fb1d1c182fd28779f145cd3b2dada47f3d2e2ecff47b.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd\n",
      "loading configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/b53ed8747a5b37964a05edc916473cff56715a812925d9dc9da210fb78034a44.1926821bfae853fe61231002dd5438ad945f4005f0254f94cc34585e6a702ae4\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-00de957f6d59d6b6.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-5377274a3eaf8348.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-29f5ee107bffb5b5.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-1bd6f35490ba32c9.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-6745bf0fe54980c6.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-8c096a6fa751090a.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-764d2f88131d981d.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-8356718c907a0a68.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/pytorch_model.bin from cache at /home/peterr/.cache/huggingface/transformers/9db74ddedd45cb8cd6233e14aee9e5ba9297e9dccd82c67e69dc91c1f1396387.31d6b2d44978dea4ae1cc6e968eee22b751827772599354d66f27aca2af4bc00\n",
      "Some weights of the model checkpoint at facebook/hubert-xlarge-ls960-ft were not used when initializing HubertForSpeechClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing HubertForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSpeechClassification were not initialized from the model checkpoint at facebook/hubert-xlarge-ls960-ft and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using amp half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 702\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1750/1750 28:40, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.107900</td>\n",
       "      <td>1.270304</td>\n",
       "      <td>0.519802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.938766</td>\n",
       "      <td>0.702970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.972300</td>\n",
       "      <td>1.078245</td>\n",
       "      <td>0.638614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.403200</td>\n",
       "      <td>1.416644</td>\n",
       "      <td>0.673267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.226100</td>\n",
       "      <td>1.564074</td>\n",
       "      <td>0.707921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.219100</td>\n",
       "      <td>1.722281</td>\n",
       "      <td>0.717822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.321800</td>\n",
       "      <td>1.676787</td>\n",
       "      <td>0.752475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1.696630</td>\n",
       "      <td>0.757426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>1.724465</td>\n",
       "      <td>0.782178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>1.672707</td>\n",
       "      <td>0.772277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175/preprocessor_config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-e8347a4b4ad081a1\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-e8347a4b4ad081a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c95d5e4ecff4cb9ad53a10a3053646f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-e8347a4b4ad081a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-bb440e43c1baa3de.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24978b50ec1e470ab9a6358b465cef0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1cd582fe01726688\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854c86e2e45d418486258060440ddf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-72734b5613839aa0.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "416138bd676c447fb145f18f189d9a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9260442a7fe0355e\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809c546878c440119785dd6e859bee8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classification problem with 5 classes: ['anger', 'fear', 'happiness', 'neutral', 'sadness']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/6e6a66209ff036c1950c074bf469284b972c51d47a2b5616058492342c5aefed.757c0a4bd6fb6d02fc8d08d3765246a0dfceff43b5c30b6f89a37f5bc41cf9a9\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/preprocessor_config.json from cache at /home/peterr/.cache/huggingface/transformers/a5ddb07fdc2b1c071a4052b0770fc830bb2700d1e63e93d18d76d6afc7fbeb8c.d4484dc1c81456a2461485e7168b04347a7b9a4e3b1ef3aba723323b33e12326\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/6e6a66209ff036c1950c074bf469284b972c51d47a2b5616058492342c5aefed.757c0a4bd6fb6d02fc8d08d3765246a0dfceff43b5c30b6f89a37f5bc41cf9a9\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/vocab.json from cache at /home/peterr/.cache/huggingface/transformers/dcb65ab05f43e19e1d0c683e4ca2a5009f813c82b2e538d2f7bf61207bfa5a93.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/tokenizer_config.json from cache at /home/peterr/.cache/huggingface/transformers/6d379fd1e1c3bd71a723979c82cc04c4a06b6d027e2b359ba86c2526bca7a23c.ea28570bd84cc806dae8a5ad416aa9fb57e169b1bf6fce0386fd890fec53e6a0\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/special_tokens_map.json from cache at /home/peterr/.cache/huggingface/transformers/e905ddc20478dfb25fd1f9e8fe2783b83b30570baff6db8f7532d9fb6b93e66d.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd\n",
      "loading configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/6e6a66209ff036c1950c074bf469284b972c51d47a2b5616058492342c5aefed.757c0a4bd6fb6d02fc8d08d3765246a0dfceff43b5c30b6f89a37f5bc41cf9a9\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-779d51f3a8211705.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-07021d0fd665679f.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-0d3ac5bd36ffc2ce.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-10fe1a04e7e70c67.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-9a3e82c6ca94b4b8.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b90baf9b4e39741a.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b4e4dd45ce662e94.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-f8e1ae8a794e0b66.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/pytorch_model.bin from cache at /home/peterr/.cache/huggingface/transformers/3964c36efc75c1687db64aaf1d970beee48cd89e4a8c6b5bd072ca7ee9ff8cc5.bb6f85ae361fc3c32f100ac2335b4609e9f7135ced8e598265e36654b51d8471\n",
      "Some weights of the model checkpoint at facebook/hubert-large-ls960-ft were not used when initializing HubertForSpeechClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing HubertForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSpeechClassification were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using amp half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 702\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1750/1750 16:19, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.112700</td>\n",
       "      <td>1.544004</td>\n",
       "      <td>0.450495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.013700</td>\n",
       "      <td>1.158458</td>\n",
       "      <td>0.584158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.962800</td>\n",
       "      <td>0.936876</td>\n",
       "      <td>0.628713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.749500</td>\n",
       "      <td>1.518030</td>\n",
       "      <td>0.628713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.628500</td>\n",
       "      <td>1.311967</td>\n",
       "      <td>0.668317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>1.366246</td>\n",
       "      <td>0.698020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>1.759784</td>\n",
       "      <td>0.658416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.885457</td>\n",
       "      <td>0.673267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>1.762518</td>\n",
       "      <td>0.688119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.870870</td>\n",
       "      <td>0.683168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175/preprocessor_config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-175] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-350] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-525] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-875] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1050] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1225] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\n",
      "Configuration saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model weights saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1575] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-e8347a4b4ad081a1\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-e8347a4b4ad081a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c95eaa4900b49adab8bf9da159fa0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-e8347a4b4ad081a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-bb440e43c1baa3de.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a299ea673be246f9bd8014fbeda54e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1cd582fe01726688\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b22660632c54dff9941074e8192f9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-large-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-72734b5613839aa0.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a7a28304f3415f8222de032eaf0da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9260442a7fe0355e\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e97ee50d7947fc98ce1782b5102e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classification problem with 5 classes: ['anger', 'fear', 'happiness', 'neutral', 'sadness']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/b53ed8747a5b37964a05edc916473cff56715a812925d9dc9da210fb78034a44.1926821bfae853fe61231002dd5438ad945f4005f0254f94cc34585e6a702ae4\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/preprocessor_config.json from cache at /home/peterr/.cache/huggingface/transformers/1a84c80cbd674725a664809a7b84a44f63215e0cfe72ead717aa2302869edb5d.d4484dc1c81456a2461485e7168b04347a7b9a4e3b1ef3aba723323b33e12326\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/b53ed8747a5b37964a05edc916473cff56715a812925d9dc9da210fb78034a44.1926821bfae853fe61231002dd5438ad945f4005f0254f94cc34585e6a702ae4\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/vocab.json from cache at /home/peterr/.cache/huggingface/transformers/d9b098b7eb8dd691982b067aafa2fc8a5fc7839a45b7ccc3abc775ad5e2a7903.8bb95990c4cc44068ae3d50c97a7e96b000a80e847578b125650dd57bf4ab6ce\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/tokenizer_config.json from cache at /home/peterr/.cache/huggingface/transformers/f62214d9f96320035803149844bdd96d0d8c656626d2214083c480a5e45a0c2e.ea28570bd84cc806dae8a5ad416aa9fb57e169b1bf6fce0386fd890fec53e6a0\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/special_tokens_map.json from cache at /home/peterr/.cache/huggingface/transformers/0dd9f421c5b57d7bce23fb1d1c182fd28779f145cd3b2dada47f3d2e2ecff47b.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd\n",
      "loading configuration file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/b53ed8747a5b37964a05edc916473cff56715a812925d9dc9da210fb78034a44.1926821bfae853fe61231002dd5438ad945f4005f0254f94cc34585e6a702ae4\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-00de957f6d59d6b6.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-5377274a3eaf8348.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-29f5ee107bffb5b5.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-1bd6f35490ba32c9.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-6745bf0fe54980c6.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-8c096a6fa751090a.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-764d2f88131d981d.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-8356718c907a0a68.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/facebook/hubert-xlarge-ls960-ft/resolve/main/pytorch_model.bin from cache at /home/peterr/.cache/huggingface/transformers/9db74ddedd45cb8cd6233e14aee9e5ba9297e9dccd82c67e69dc91c1f1396387.31d6b2d44978dea4ae1cc6e968eee22b751827772599354d66f27aca2af4bc00\n",
      "Some weights of the model checkpoint at facebook/hubert-xlarge-ls960-ft were not used when initializing HubertForSpeechClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing HubertForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSpeechClassification were not initialized from the model checkpoint at facebook/hubert-xlarge-ls960-ft and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using amp half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 702\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1750/1750 28:42, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.860900</td>\n",
       "      <td>1.666433</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.458200</td>\n",
       "      <td>1.301986</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.918600</td>\n",
       "      <td>0.959768</td>\n",
       "      <td>0.707921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>1.217390</td>\n",
       "      <td>0.702970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.366500</td>\n",
       "      <td>1.430391</td>\n",
       "      <td>0.698020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.429100</td>\n",
       "      <td>1.408555</td>\n",
       "      <td>0.727723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>1.459827</td>\n",
       "      <td>0.752475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.623628</td>\n",
       "      <td>0.772277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>1.654729</td>\n",
       "      <td>0.762376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.690131</td>\n",
       "      <td>0.752475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175/preprocessor_config.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-175] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-350] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-525] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-700] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-875] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1050] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1225] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1400] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\n",
      "Configuration saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model weights saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "Feature extractor saved in models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Deleting older checkpoint [models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1575] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-e8347a4b4ad081a1\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-e8347a4b4ad081a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235984592305415eac643085b4b5f152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-e8347a4b4ad081a1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-bb440e43c1baa3de.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595d2c50e396452f84a0fe47abc6d88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1cd582fe01726688\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0b3e11ad884b39a37833ad809f16ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:52: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "loading feature extractor configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/preprocessor_config.json\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/vocab.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/tokenizer_config.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/added_tokens.json. We won't load it.\n",
      "Didn't find file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./tokenizer_config.json. We won't load it.\n",
      "Didn't find file ./added_tokens.json. We won't load it.\n",
      "Didn't find file ./special_tokens_map.json. We won't load it.\n",
      "loading file ./vocab.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "Adding <s> to the vocabulary\n",
      "Adding </s> to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-xlarge-ls960-ft\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForSpeechClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1280,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5120,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooling_mode\": \"mean\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading weights file models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing HubertForSpeechClassification.\n",
      "\n",
      "All the weights of HubertForSpeechClassification were initialized from the model checkpoint at models/facebook_hubert-xlarge-ls960-ft_emotion_10_epochs_/checkpoint-1750.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use HubertForSpeechClassification for predictions without further training.\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-1cd582fe01726688/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-72734b5613839aa0.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da21bb96ac824382830e5eccc9ad8684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9260442a7fe0355e\n",
      "Reusing dataset csv (/home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93861d7529e64958948018fb73d53ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classification problem with 5 classes: ['anger', 'fear', 'happiness', 'neutral', 'sadness']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/6e6a66209ff036c1950c074bf469284b972c51d47a2b5616058492342c5aefed.757c0a4bd6fb6d02fc8d08d3765246a0dfceff43b5c30b6f89a37f5bc41cf9a9\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"finetuning_task\": \"wav2vec2_clf\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"fear\",\n",
      "    \"2\": \"happiness\",\n",
      "    \"3\": \"neutral\",\n",
      "    \"4\": \"sadness\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"fear\": 1,\n",
      "    \"happiness\": 2,\n",
      "    \"neutral\": 3,\n",
      "    \"sadness\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading feature extractor configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/preprocessor_config.json from cache at /home/peterr/.cache/huggingface/transformers/a5ddb07fdc2b1c071a4052b0770fc830bb2700d1e63e93d18d76d6afc7fbeb8c.d4484dc1c81456a2461485e7168b04347a7b9a4e3b1ef3aba723323b33e12326\n",
      "Feature extractor Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/6e6a66209ff036c1950c074bf469284b972c51d47a2b5616058492342c5aefed.757c0a4bd6fb6d02fc8d08d3765246a0dfceff43b5c30b6f89a37f5bc41cf9a9\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/vocab.json from cache at /home/peterr/.cache/huggingface/transformers/dcb65ab05f43e19e1d0c683e4ca2a5009f813c82b2e538d2f7bf61207bfa5a93.7c838a0a103758bad6ef4922531682da23a8b1c45d25f8d8e7a6d857c0b26544\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/tokenizer_config.json from cache at /home/peterr/.cache/huggingface/transformers/6d379fd1e1c3bd71a723979c82cc04c4a06b6d027e2b359ba86c2526bca7a23c.ea28570bd84cc806dae8a5ad416aa9fb57e169b1bf6fce0386fd890fec53e6a0\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/special_tokens_map.json from cache at /home/peterr/.cache/huggingface/transformers/e905ddc20478dfb25fd1f9e8fe2783b83b30570baff6db8f7532d9fb6b93e66d.9d6cd81ef646692fb1c169a880161ea1cb95f49694f220aced9b704b457e51dd\n",
      "loading configuration file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/config.json from cache at /home/peterr/.cache/huggingface/transformers/6e6a66209ff036c1950c074bf469284b972c51d47a2b5616058492342c5aefed.757c0a4bd6fb6d02fc8d08d3765246a0dfceff43b5c30b6f89a37f5bc41cf9a9\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-large-ls960-ft\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-779d51f3a8211705.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-07021d0fd665679f.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-0d3ac5bd36ffc2ce.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-10fe1a04e7e70c67.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-9a3e82c6ca94b4b8.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b90baf9b4e39741a.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b4e4dd45ce662e94.arrow\n",
      "Loading cached processed dataset at /home/peterr/.cache/huggingface/datasets/csv/default-9260442a7fe0355e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-f8e1ae8a794e0b66.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/facebook/hubert-large-ls960-ft/resolve/main/pytorch_model.bin from cache at /home/peterr/.cache/huggingface/transformers/3964c36efc75c1687db64aaf1d970beee48cd89e4a8c6b5bd072ca7ee9ff8cc5.bb6f85ae361fc3c32f100ac2335b4609e9f7135ced8e598265e36654b51d8471\n",
      "Some weights of the model checkpoint at facebook/hubert-large-ls960-ft were not used when initializing HubertForSpeechClassification: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing HubertForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSpeechClassification were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using amp half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `HubertForSpeechClassification.forward` and have been ignored: arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target. If arousal_annotation_phase, discrete_emotion_collection_phase, expression, manual_transcription, discrete_emotion_annotation_phase, age, gender, split, Unnamed: 0, valence_annotation_phase, path, speaker_id, utterance_id, target are not expected by `HubertForSpeechClassification.forward`,  you can safely ignore this message.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 702\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  16/1750 00:06 < 14:18, 2.02 it/s, Epoch 0.09/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "checkpoints = [\n",
    "    # \"facebook/wav2vec2-large-slavic-voxpopuli-v2\",\n",
    "    # \"facebook/wav2vec2-large-960h-lv60-self\",\n",
    "    # \"classla/wav2vec2-large-slavic-parlaspeech-hr\",\n",
    "    \"facebook/hubert-large-ls960-ft\",\n",
    "    \"facebook/hubert-xlarge-ls960-ft\",\n",
    "]\n",
    "optimal_epochs = {\n",
    "    \"facebook/wav2vec2-large-960h-lv60-self\": 9,\n",
    "    \"facebook/wav2vec2-large-slavic-voxpopuli-v2\": 11,\n",
    "    \"classla/wav2vec2-large-slavic-parlaspeech-hr\": 7,  \n",
    "    \"facebook/hubert-large-ls960-ft\": 10,\n",
    "    \"facebook/hubert-xlarge-ls960-ft\": 10,\n",
    "    \n",
    "}\n",
    "from utils import train_model, eval_model\n",
    "from hubertutils import train_model as hu_train_model, eval_model as hu_eval_model\n",
    "for checkpoint in checkpoints * 10:\n",
    "    import os\n",
    "    os.system(\"rm -r models/*\")\n",
    "    train_config = dict(\n",
    "        model_name_or_path = checkpoint,\n",
    "        TASK = \"emotion_10_epochs\",\n",
    "        NUM_EPOCH = optimal_epochs.get(checkpoint),\n",
    "        output_column = \"target\",\n",
    "        input_column = \"path\",\n",
    "        data_files = {\n",
    "            \"train\": \"007_train.csv\",\n",
    "            \"validation\": \"007_dev.csv\",\n",
    "        },\n",
    "        clip_seconds = 10\n",
    "    )\n",
    "\n",
    "    output_dir = hu_train_model(train_config)\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "    found_path = str(list(Path(output_dir).glob(\"checkpoint-*\"))[0])\n",
    "    for split in \"dev test\".split():\n",
    "        results = []\n",
    "        # print(f\"For checkpoint: {checkpoint} a path was found: \", found_path)\n",
    "        eval_config = dict(\n",
    "            output_column = \"target\",\n",
    "            model_name_or_path= found_path ,\n",
    "            eval_file= f\"007_{split}.csv\"\n",
    "        )\n",
    "\n",
    "        y_true, y_pred = hu_eval_model(eval_config)\n",
    "        import datetime\n",
    "        time = str(datetime.datetime.now())\n",
    "        results.append(\n",
    "            {\n",
    "                **eval_config, \n",
    "                **train_config,\n",
    "                \"split\": split,\n",
    "                \"y_true\": y_true, \n",
    "                \"y_pred\": y_pred,\n",
    "                \"time\": time,\n",
    "                        })\n",
    "        content = pd.DataFrame(data=results).to_json(None, \n",
    "                                           orient=\"records\",\n",
    "                                           lines=True,\n",
    "                                           )\n",
    "        with open(\"009_hubert_training.jsonl\", \"a\") as f:\n",
    "            f.writelines(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f6f5766036ee03d059e365a942add07f79c17033585e9357ee8157d52fe6bb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
